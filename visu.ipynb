{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/donghwa/anaconda3/envs/lab/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/donghwa/Documents/cnc/HAM/tf-rnn-attention/train.py:62: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/donghwa/Documents/cnc/HAM/tf-rnn-attention/train.py:74: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/donghwa/anaconda3/envs/lab/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/donghwa/anaconda3/envs/lab/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w_embed:0' shape=(10000, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/gates/kernel:0' shape=(250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/gates/bias:0' shape=(300,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/candidate/kernel:0' shape=(250, 150) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/candidate/bias:0' shape=(150,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/gates/kernel:0' shape=(250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/gates/bias:0' shape=(300,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/candidate/kernel:0' shape=(250, 150) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/candidate/bias:0' shape=(150,) dtype=float32_ref>,\n",
       " <tf.Variable 'w_omega:0' shape=(300, 50) dtype=float32_ref>,\n",
       " <tf.Variable 'b_omega:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'u_omega:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'Fully_connected_layer/Variable:0' shape=(300, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Fully_connected_layer/Variable_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Metrics/beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Metrics/beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'w_embed/Adam:0' shape=(10000, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'w_embed/Adam_1:0' shape=(10000, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/gates/kernel/Adam:0' shape=(250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/gates/kernel/Adam_1:0' shape=(250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/gates/bias/Adam:0' shape=(300,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/gates/bias/Adam_1:0' shape=(300,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/candidate/kernel/Adam:0' shape=(250, 150) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/candidate/kernel/Adam_1:0' shape=(250, 150) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/candidate/bias/Adam:0' shape=(150,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/fw/gru_cell/candidate/bias/Adam_1:0' shape=(150,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/gates/kernel/Adam:0' shape=(250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/gates/kernel/Adam_1:0' shape=(250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/gates/bias/Adam:0' shape=(300,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/gates/bias/Adam_1:0' shape=(300,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/candidate/kernel/Adam:0' shape=(250, 150) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/candidate/kernel/Adam_1:0' shape=(250, 150) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/candidate/bias/Adam:0' shape=(150,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_rnn/bw/gru_cell/candidate/bias/Adam_1:0' shape=(150,) dtype=float32_ref>,\n",
       " <tf.Variable 'w_omega/Adam:0' shape=(300, 50) dtype=float32_ref>,\n",
       " <tf.Variable 'w_omega/Adam_1:0' shape=(300, 50) dtype=float32_ref>,\n",
       " <tf.Variable 'b_omega/Adam:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'b_omega/Adam_1:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'u_omega/Adam:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'u_omega/Adam_1:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'Fully_connected_layer/Variable/Adam:0' shape=(300, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Fully_connected_layer/Variable/Adam_1:0' shape=(300, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Fully_connected_layer/Variable_1/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Fully_connected_layer/Variable_1/Adam_1:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_dir/model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate alpha coefficients for the first test example\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "\n",
    "    x_batch_test, y_batch_test = X_test[0:10], y_test[0:10]\n",
    "    seq_len_test = np.sum(x_batch_test !=0, axis=1) # actual lengths of sequences\n",
    "    alphas_test = sess.run([alphas], feed_dict={batch_ph: x_batch_test, target_ph: y_batch_test,\n",
    "                                                keep_prob_ph: 1.0,\n",
    "                                                batch_size_ph:len(x_batch_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 250)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build correct mapping from word to index and inverse\n",
    "word_index = imdb.get_word_index()\n",
    "word_index = {word: index + INDEX_FROM for word, index in word_index.items()}\n",
    "word_index[\":PAD:\"] = 0\n",
    "word_index[\":START:\"] = 1\n",
    "word_index[\":UNK:\"] = 2\n",
    "index_word = {value: key for key, value in word_index.items()}\n",
    "# Represent the sample by words rather than indices\n",
    "WORDS = list([list(map(index_word.get, x)) for x in x_batch_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':START:', 'please', 'give', 'this', 'one', 'a', 'miss', 'br', 'br', ':UNK:', ':UNK:', 'and', 'the', 'rest', 'of', 'the', 'cast', 'rendered', 'terrible', 'performances', 'the', 'show', 'is', 'flat', 'flat', 'flat', 'br', 'br', 'i', \"don't\", 'know', 'how', 'michael', 'madison', 'could', 'have', 'allowed', 'this', 'one', 'on', 'his', 'plate', 'he', 'almost', 'seemed', 'to', 'know', 'this', \"wasn't\", 'going', 'to', 'work', 'out', 'and', 'his', 'performance', 'was', 'quite', ':UNK:', 'so', 'all', 'you', 'madison', 'fans', 'give', 'this', 'a', 'miss', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:', ':PAD:']\n"
     ]
    }
   ],
   "source": [
    "print(WORDS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[6.23109145e-03, 7.92000908e-03, 8.31867289e-03, ...,\n",
       "         1.58739625e-04, 1.73065317e-04, 1.92631618e-04],\n",
       "        [3.91616207e-03, 3.96514591e-03, 3.32271331e-03, ...,\n",
       "         1.19216675e-02, 1.21548232e-02, 1.25672687e-02],\n",
       "        [2.46916991e-03, 2.41376786e-03, 2.59333150e-03, ...,\n",
       "         9.21661872e-03, 1.04165031e-02, 1.10096373e-02],\n",
       "        ...,\n",
       "        [2.78337742e-04, 2.87979608e-04, 2.94701458e-04, ...,\n",
       "         4.67624523e-05, 5.09756428e-05, 5.67466595e-05],\n",
       "        [4.58475715e-03, 4.27286187e-03, 4.44687391e-03, ...,\n",
       "         1.12041284e-03, 1.22175773e-03, 1.36021606e-03],\n",
       "        [3.79521237e-03, 4.00373898e-03, 3.38824792e-03, ...,\n",
       "         5.68107329e-03, 4.63395612e-03, 5.79124503e-03]], dtype=float32)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Open visualization.html to checkout the attention coefficients visualization.\n"
     ]
    }
   ],
   "source": [
    "# Save visualization as HTML\n",
    "with open(\"visualization.html\", \"a\") as html_file:\n",
    "    html_file.write('<head>\\n<meta charset=\"UTF-8\">\\n</head>\\n')\n",
    "    for words, alphas, y in zip(WORDS, alphas_test[0], y_batch_test):\n",
    "        html_file.write('<font style=\"background: rgb(255, 255, 250)\">%s</font> ' % (y))    \n",
    "        for word, alpha in zip(words, alphas / alphas.max()):\n",
    "            if word == \":START:\":\n",
    "                continue\n",
    "            elif word == \":PAD:\":\n",
    "                continue\n",
    "            if y ==1:\n",
    "                html_file.write('<font style=\"background: rgba(95, 95, 250, %f)\">%s</font>\\n' % (alpha, word))\n",
    "            else:\n",
    "                html_file.write('<font style=\"background: rgba(250, 95, 95, %f)\">%s</font>\\n' % (alpha, word))\n",
    "        html_file.write('<br>')\n",
    "print('\\nOpen visualization.html to checkout the attention coefficients visualization.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
